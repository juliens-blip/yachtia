# ğŸ¤– MISSION CODEX - AmÃ©lioration Pipeline RAG

**Agent:** CODEX (Backend/Data specialist)  
**ModÃ¨le recommandÃ©:** sonnet  
**PrioritÃ©:** HIGH  
**DurÃ©e estimÃ©e:** 2h

---

## ğŸ“‹ CONTEXTE

Le systÃ¨me Yacht Legal AI utilise Gemini pour analyser des PDFs juridiques via RAG.  
**ProblÃ¨me:** Gemini ne rÃ©cupÃ¨re pas assez de chunks pertinents et fallback trop vite sur internet.

**Repo:** `/home/julien/Documents/iayacht/yacht-legal-ai`

---

## ğŸ¯ OBJECTIFS

AmÃ©liorer le pipeline RAG pour:
1. RÃ©cupÃ©rer plus de chunks pertinents (5 â†’ 10)
2. Ajouter mÃ©tadonnÃ©es contextuelles aux chunks
3. ImplÃ©menter re-ranking sÃ©mantique

---

## âœ… TODO 1: AmÃ©liorer le Chunking PDF

**Fichier cible:** `lib/chunker.ts`

**Modifications requises:**

1. **Augmenter overlap:**
   - Actuellement: 100 tokens
   - Nouveau: 200 tokens
   - Permet meilleure continuitÃ© entre chunks

2. **Ajouter mÃ©tadonnÃ©es:**
   ```typescript
   interface ChunkMetadata {
     section?: string;      // Ex: "Article 5.2"
     headers?: string[];    // Titres de sections parentes
     page: number;
     chunk_index: number;
   }
   ```

3. **PrÃ©server structures:**
   - DÃ©tecter et ne pas couper: listes, tables, paragraphes juridiques
   - Exemple: Si un paragraphe fait 450 tokens, le garder intact plutÃ´t que le couper

**Test de validation:**
```typescript
const chunks = await processPDF(testPDF);
assert(chunks[0].overlap === 200);
assert(chunks[0].metadata?.page !== undefined);
```

---

## âœ… TODO 2: Optimiser search_documents (SQL)

**Nouveau fichier:** `MIGRATION_IMPROVE_SEARCH.sql`

**Modifications fonction Supabase:**

```sql
CREATE OR REPLACE FUNCTION search_documents(
  query_embedding vector(768),
  match_threshold float DEFAULT 0.6,  -- â† CHANGÃ‰ de 0.7
  match_count int DEFAULT 10,         -- â† CHANGÃ‰ de 5
  filter_category varchar DEFAULT NULL,
  use_reranking boolean DEFAULT TRUE  -- â† NOUVEAU paramÃ¨tre
)
RETURNS TABLE (
  -- ... colonnes identiques Ã  l'actuel
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT
    dc.id AS chunk_id,
    d.id AS document_id,
    d.name AS document_name,
    d.category,
    dc.chunk_text,
    1 - (dc.chunk_vector <=> query_embedding) AS similarity,
    dc.page_number,
    dc.chunk_index,
    d.source_url
  FROM document_chunks dc
  JOIN documents d ON dc.document_id = d.id
  WHERE
    (1 - (dc.chunk_vector <=> query_embedding)) > match_threshold
    AND (filter_category IS NULL OR d.category = filter_category)
    AND d.is_public = TRUE
  ORDER BY dc.chunk_vector <=> query_embedding
  LIMIT match_count;
END;
$$;
```

**Raisons des changements:**
- `match_threshold 0.6`: capture plus de candidats (moins strict)
- `match_count 10`: fournit plus de chunks au re-ranker
- `use_reranking`: flag pour activer re-ranking cÃ´tÃ© application

---

## âœ… TODO 3: ImplÃ©menter Re-ranking

**Nouveau fichier:** `lib/reranker.ts`

**Objectif:** Re-classer les chunks rÃ©cupÃ©rÃ©s en combinant similaritÃ© vectorielle + sÃ©mantique textuelle.

```typescript
/**
 * Re-rank chunks using hybrid scoring
 * @param query - User question
 * @param chunks - Chunks from vector search
 * @param topK - Number of top chunks to return
 */
export async function rerankChunks(
  query: string,
  chunks: Array<{
    chunk_text: string;
    similarity: number;
    metadata?: Record<string, any>;
  }>,
  topK: number = 5
): Promise<Array<{
  chunk_text: string;
  score: number;
  metadata?: Record<string, any>;
}>> {
  // 1. Calculer similaritÃ© sÃ©mantique avec la question
  const semanticScores = await Promise.all(
    chunks.map(chunk => computeSemanticSimilarity(query, chunk.chunk_text))
  );
  
  // 2. Combiner scores (50% vector + 50% semantic)
  const hybridScores = chunks.map((chunk, i) => ({
    ...chunk,
    score: (chunk.similarity * 0.5) + (semanticScores[i] * 0.5)
  }));
  
  // 3. Trier et retourner top K
  return hybridScores
    .sort((a, b) => b.score - a.score)
    .slice(0, topK);
}

/**
 * Compute semantic similarity (simple keyword overlap for MVP)
 * TODO: Use Gemini embeddings for better results
 */
function computeSemanticSimilarity(query: string, text: string): number {
  const queryWords = query.toLowerCase().split(/\s+/);
  const textWords = text.toLowerCase().split(/\s+/);
  
  const overlap = queryWords.filter(word => textWords.includes(word)).length;
  return overlap / queryWords.length;
}
```

**IntÃ©gration dans `lib/rag-pipeline.ts`:**

```typescript
import { rerankChunks } from './reranker';

export async function retrieveRelevantChunks(question: string) {
  // 1. Vector search (rÃ©cupÃ¨re 10 candidats)
  const candidates = await searchDocuments(embedding, 0.6, 10);
  
  // 2. Re-rank pour top 5
  const reranked = await rerankChunks(question, candidates, 5);
  
  return reranked;
}
```

---

## ğŸ§ª TESTS Ã€ CRÃ‰ER

**Fichier:** `scripts/test-rag-improvements.ts`

```typescript
#!/usr/bin/env tsx

import { processPDF } from '../lib/chunker';
import { searchDocuments } from '../lib/supabase';
import { rerankChunks } from '../lib/reranker';
import { generateEmbedding } from '../lib/gemini';

async function testSuite() {
  console.log('ğŸ§ª Test 1: Chunking avec overlap 200');
  const chunks = await processPDF('./test-docs/sample.pdf');
  assert(chunks[0].overlap === 200, 'Overlap devrait Ãªtre 200');
  assert(chunks[0].metadata?.page !== undefined, 'MÃ©tadonnÃ©es page manquantes');
  console.log('âœ… Test 1 passÃ©\n');
  
  console.log('ğŸ§ª Test 2: search_documents retourne 10 rÃ©sultats');
  const embedding = await generateEmbedding('test query');
  const results = await searchDocuments(embedding, 0.6, 10);
  assert(results.length <= 10, `Devrait retourner max 10, reÃ§u ${results.length}`);
  console.log('âœ… Test 2 passÃ©\n');
  
  console.log('ğŸ§ª Test 3: Re-ranking amÃ©liore pertinence');
  const beforeScore = avgScore(results);
  const reranked = await rerankChunks('test query', results, 5);
  const afterScore = avgScore(reranked);
  assert(afterScore >= beforeScore * 1.1, 'Re-ranking devrait amÃ©liorer de 10%+');
  console.log(`âœ… Test 3 passÃ© (amÃ©lioration: ${((afterScore/beforeScore - 1) * 100).toFixed(1)}%)\n`);
  
  console.log('ğŸ‰ Tous les tests passÃ©s !');
}

testSuite().catch(console.error);
```

**Script npm:** Ajouter dans `package.json`:
```json
{
  "scripts": {
    "test:rag": "tsx scripts/test-rag-improvements.ts"
  }
}
```

---

## ğŸ“Š CRITÃˆRES DE SUCCÃˆS

| CritÃ¨re | Attendu | VÃ©rification |
|---------|---------|--------------|
| Overlap chunks | 200 tokens | Test unitaire |
| MÃ©tadonnÃ©es prÃ©sentes | âœ… | Test unitaire |
| search_documents threshold | 0.6 | SQL migration |
| search_documents count | 10 | SQL migration |
| Re-ranker implÃ©mentÃ© | âœ… | Code review |
| Tests passent | 3/3 âœ… | `npm run test:rag` |

---

## ğŸ“ LIVRABLE

Ã€ la fin de la mission, fournir:

1. **Liste fichiers modifiÃ©s:**
   - `lib/chunker.ts` (diff montrant changements)
   - `lib/rag-pipeline.ts` (intÃ©gration re-ranking)
   - `MIGRATION_IMPROVE_SEARCH.sql` (nouveau fichier)

2. **Nouveau fichier crÃ©Ã©:**
   - `lib/reranker.ts` (module complet)
   - `scripts/test-rag-improvements.ts` (suite de tests)

3. **RÃ©sultats tests:**
   ```
   ğŸ§ª Test 1: Chunking avec overlap 200 âœ…
   ğŸ§ª Test 2: search_documents retourne 10 rÃ©sultats âœ…
   ğŸ§ª Test 3: Re-ranking amÃ©liore pertinence âœ…
   
   ğŸ‰ Tous les tests passÃ©s !
   ```

4. **Metrics:**
   - Chunks rÃ©cupÃ©rÃ©s: 5 â†’ 10 (Ã—2)
   - AmÃ©lioration pertinence re-ranking: +X%
   - Overlap chunks: 100 â†’ 200 tokens

---

## âš ï¸ CONTRAINTES

- **Ne PAS** casser la compatibilitÃ© SQL existante
- **Ne PAS** modifier le schema de la table `document_chunks`
- **Garder** les noms de colonnes identiques dans `search_documents`
- **Tester** avant de livrer

---

**CODEX, c'est parti ! Attends confirmation de l'orchestrateur avant de commencer.**
