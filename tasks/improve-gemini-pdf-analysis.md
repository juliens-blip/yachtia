# ğŸ¯ Task: AmÃ©liorer l'Analyse PDF par Gemini

**Orchestrateur:** Claude  
**Date:** 2026-01-22  
**Objectif:** AmÃ©liorer la capacitÃ© de Gemini Ã  parser et analyser les PDFs avant de recourir Ã  des donnÃ©es internet

## ğŸ“‹ Contexte
Gemini rÃ©pond parfois avec des donnÃ©es internet sans avoir correctement analysÃ© les documents PDF disponibles dans la base RAG. Il faut amÃ©liorer:
1. La lecture/parsing des PDFs
2. L'analyse sÃ©mantique des questions
3. Le recrutement des chunks pertinents
4. La profondeur d'analyse avant fallback internet

---

## ğŸ¤– Distribution des TÃ¢ches

### **CODEX** - AmÃ©lioration du Pipeline RAG
**PrioritÃ©:** HIGH  
**DurÃ©e estimÃ©e:** 2h

#### TODO CODEX
1. **AmÃ©liorer la fonction de chunking PDF** (`lib/pdf-processor.ts`)
   - âœ… Augmenter overlap entre chunks (actuellement 100 â†’ 200 tokens)
   - âœ… Ajouter mÃ©tadonnÃ©es contextuelles (section, headers)
   - âœ… DÃ©tecter et prÃ©server structures (listes, tables)

2. **Optimiser la fonction search_documents** (Supabase)
   - âœ… Abaisser match_threshold (0.7 â†’ 0.6 pour plus de rÃ©sultats)
   - âœ… Augmenter match_count (5 â†’ 10 chunks)
   - âœ… Ajouter re-ranking sÃ©mantique post-search

3. **Tests de validation**
   - âœ… CrÃ©er script test avec 5 questions types
   - âœ… VÃ©rifier nombre de chunks rÃ©cupÃ©rÃ©s
   - âœ… Mesurer pertinence moyenne

**Fichiers Ã  modifier:**
- `yacht-legal-ai/lib/pdf-processor.ts`
- `yacht-legal-ai/MIGRATION_FIX_TYPE.sql` (search_documents function)
- `yacht-legal-ai/lib/rag-pipeline.ts`

**Validation:**
```bash
npm run test:rag
```

---

### **ANTIGRAVIT** - AmÃ©lioration du Prompt Gemini
**PrioritÃ©:** HIGH  
**DurÃ©e estimÃ©e:** 1.5h

#### TODO ANTIGRAVIT
1. **Modifier le system prompt** (`lib/gemini.ts`)
   - âœ… Ajouter instruction: "Analyser PROFONDÃ‰MENT tous les chunks fournis"
   - âœ… Forcer citation des sources PDF avant internet
   - âœ… Demander justification si "pas de rÃ©ponse dans docs"

2. **Ajouter Ã©tape de pre-processing de la question**
   - âœ… Extraire keywords juridiques de la question
   - âœ… Reformuler en 2-3 variantes sÃ©mantiques
   - âœ… Chercher avec chaque variante

3. **ImplÃ©menter logging dÃ©taillÃ©**
   - âœ… Logger les chunks envoyÃ©s Ã  Gemini
   - âœ… Logger la rÃ©ponse + sources citÃ©es
   - âœ… DÃ©tecter fallback internet vs RAG

**Fichiers Ã  modifier:**
- `yacht-legal-ai/lib/gemini.ts`
- `yacht-legal-ai/app/api/chat/route.ts`

**Validation:**
```bash
npm run dev
# Tester avec question type: "Quelles sont les obligations du vendeur dans un contrat de vente de yacht?"
```

---

## ğŸ§ª Tests Type Ralph (Agent)

### Phase 1: Tests Unitaires (CODEX)
```bash
# Test chunking amÃ©liorÃ©
node scripts/test-chunking.js

# Test search_documents avec nouveaux paramÃ¨tres
psql -f test-search-function.sql

# Test re-ranking
npm run test:rerank
```

**CritÃ¨res de succÃ¨s:**
- âœ… Chunks avec 200 tokens overlap
- âœ… MÃ©tadonnÃ©es prÃ©sentes (section, page)
- âœ… search_documents retourne 10+ rÃ©sultats si disponibles
- âœ… Re-ranking amÃ©liore pertinence de 20%+

---

### Phase 2: Tests d'IntÃ©gration (ANTIGRAVIT)
```bash
# Test du nouveau prompt
curl -X POST localhost:3000/api/chat \
  -d '{"message":"Quelles sont les obligations du vendeur?"}' \
  | jq '.sources'

# VÃ©rifier logging
tail -f logs/gemini-rag.log
```

**CritÃ¨res de succÃ¨s:**
- âœ… Gemini cite 3+ chunks PDF dans rÃ©ponse
- âœ… Pas de fallback internet si chunks pertinents
- âœ… Logs montrent analyse dÃ©taillÃ©e

---

### Phase 3: Tests End-to-End (ORCHESTRATEUR Claude)
```bash
# 5 questions test
npm run test:e2e-rag
```

**Questions types:**
1. "Quelles sont les obligations du vendeur dans un contrat de vente?"
2. "Comment fonctionne la garantie des vices cachÃ©s?"
3. "Quelle est la procÃ©dure pour un litige maritime?"
4. "Quels documents sont nÃ©cessaires pour l'immatriculation?"
5. "Quelles sont les responsabilitÃ©s du capitaine?"

**CritÃ¨res de succÃ¨s:**
- âœ… 4/5 questions rÃ©pondues avec sources PDF uniquement
- âœ… Latence < 3s par rÃ©ponse
- âœ… Chunks pertinents = 80%+ de la rÃ©ponse

---

## ğŸ“Š MÃ©triques de SuccÃ¨s

| MÃ©trique | Avant | Objectif | Status |
|----------|-------|----------|--------|
| Chunks rÃ©cupÃ©rÃ©s | 5 | 10 | â³ |
| Pertinence chunks | ~60% | 80%+ | â³ |
| Citations PDF | ~40% | 80%+ | â³ |
| Fallback internet | ~60% | <20% | â³ |
| Latence moyenne | 2-3s | <3s | â³ |

---

## ğŸ”„ Workflow d'Orchestration

1. **CODEX START** (parallel execution)
   - Attendre completion des 3 TODOs
   - Soumettre rapport de test

2. **ANTIGRAVIT START** (parallel execution)
   - Attendre completion des 3 TODOs
   - Soumettre rapport de test

3. **CLAUDE REVIEW** (sequential)
   - Analyser rapports CODEX + ANTIGRAVIT
   - Lancer tests Phase 3
   - Valider mÃ©triques

4. **ITERATION SI BESOIN**
   - Si mÃ©triques < objectif â†’ nouvelle itÃ©ration
   - Ajuster prompts/paramÃ¨tres

---

## ğŸ“ Notes pour LLMs

**CODEX:** Focus sur performance et qualitÃ© des chunks. Ne pas casser la compatibilitÃ© SQL existante.

**ANTIGRAVIT:** Le prompt doit rester conversationnel. Pas de "robot lawyer" vibes.

**CLAUDE:** Tu valides et orchestres. Si conflit entre CODEX/ANTIGRAVIT, tu dÃ©cides.

---

## âœ… Checklist Finale

- [ ] CODEX: 3 TODOs complÃ©tÃ©s + tests passÃ©s
- [ ] ANTIGRAVIT: 3 TODOs complÃ©tÃ©s + tests passÃ©s
- [ ] CLAUDE: Tests E2E passÃ©s (4/5 questions)
- [ ] MÃ©triques objectifs atteints
- [ ] Documentation mise Ã  jour
- [ ] Commit + push changes
