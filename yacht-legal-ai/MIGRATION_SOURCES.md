# üìù Migration - Affichage Sources avec Liens

## R√©sum√©

‚úÖ **Gemini r√©capitule maintenant les sources utilis√©es avec liens en bas du chat**  
‚úÖ **PDFs t√©l√©charg√©s automatiquement** - pas besoin de les t√©l√©charger manuellement

## üîß Changements Effectu√©s

### 1Ô∏è‚É£ Base de Donn√©es - Migration SQL

**Fichier:** [database/migrations/013_add_source_url_to_search.sql](file:///home/julien/Documents/iayacht/yacht-legal-ai/database/migrations/013_add_source_url_to_search.sql)

La fonction `search_documents()` retourne maintenant le champ `source_url` pour chaque chunk.

**√Ä ex√©cuter dans Supabase SQL Editor :**

```sql
-- Migration 013: Add source_url to search_documents function

-- Drop existing function
DROP FUNCTION IF EXISTS search_documents(vector, float, int, varchar);

-- Recreate with source_url
CREATE OR REPLACE FUNCTION search_documents(
  query_embedding vector(768),
  match_threshold float DEFAULT 0.7,
  match_count int DEFAULT 5,
  filter_category varchar DEFAULT NULL
)
RETURNS TABLE (
  chunk_id uuid,
  document_id uuid,
  document_name varchar,
  category varchar,
  chunk_text text,
  similarity float,
  page_number int,
  chunk_index int,
  source_url text
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT
    dc.id AS chunk_id,
    d.id AS document_id,
    d.name AS document_name,
    d.category,
    dc.chunk_text,
    1 - (dc.chunk_vector <=> query_embedding) AS similarity,
    dc.page_number,
    dc.chunk_index,
    d.source_url
  FROM document_chunks dc
  JOIN documents d ON dc.document_id = d.id
  WHERE
    (1 - (dc.chunk_vector <=> query_embedding)) > match_threshold
    AND (filter_category IS NULL OR d.category = filter_category)
    AND d.is_public = TRUE
  ORDER BY dc.chunk_vector <=> query_embedding
  LIMIT match_count;
END;
$$;

COMMENT ON FUNCTION search_documents IS 'Semantic search with source URLs. Returns top-K chunks with document source URLs for citation.';
```

### 2Ô∏è‚É£ Backend - Gemini API

**Fichier:** [lib/gemini.ts](file:///home/julien/Documents/iayacht/yacht-legal-ai/lib/gemini.ts)

- ‚úÖ Nouveau type `SourceReference` avec `name`, `category`, `url`
- ‚úÖ `generateAnswer()` retourne maintenant `{ answer, sources, groundingMetadata }`
- ‚úÖ Extraction automatique des sources uniques depuis les m√©tadonn√©es

### 3Ô∏è‚É£ Backend - RAG Pipeline

**Fichier:** [lib/rag-pipeline.ts](file:///home/julien/Documents/iayacht/yacht-legal-ai/lib/rag-pipeline.ts)

- ‚úÖ `RelevantChunk` inclut maintenant `sourceUrl?: string`
- ‚úÖ `SearchDocumentsRow` inclut `source_url?: string`

### 4Ô∏è‚É£ API Chat Route

**Fichier:** [app/api/chat/route.ts](file:///home/julien/Documents/iayacht/yacht-legal-ai/app/api/chat/route.ts)

- ‚úÖ Passage des `contextMetadata` √† `generateAnswer()`
- ‚úÖ Retour des sources Gemini format√©es avec URLs

### 5Ô∏è‚É£ Frontend - Affichage Sources

**Fichier:** [components/MarkdownRenderer.tsx](file:///home/julien/Documents/iayacht/yacht-legal-ai/components/MarkdownRenderer.tsx)

Le composant affiche d√©j√† les sources en bas du message avec:
- üìö Section "Sources (X)" avec badge "Recherche web activ√©e" si applicable
- üîó Liens cliquables vers les URLs sources
- üè∑Ô∏è Badge cat√©gorie
- üìä Pourcentage de pertinence

## üì¶ Instructions d'Application

### √âtape 1: Appliquer la migration SQL

```bash
# Option A: Via Supabase Dashboard
# 1. Aller sur https://supabase.com/dashboard
# 2. Ouvrir SQL Editor
# 3. Copier-coller le contenu de database/migrations/013_add_source_url_to_search.sql
# 4. Ex√©cuter

# Option B: Via script (si configur√©)
cd yacht-legal-ai
npm run db:migrate
```

### √âtape 2: V√©rifier que les documents ont bien `source_url`

```sql
-- V√©rifier dans Supabase SQL Editor
SELECT name, category, source_url 
FROM documents 
WHERE source_url IS NOT NULL 
LIMIT 10;
```

Si `source_url` est vide pour certains docs:

```sql
-- Mettre √† jour les docs existants avec file_url comme fallback
UPDATE documents 
SET source_url = file_url 
WHERE source_url IS NULL AND file_url IS NOT NULL;
```

### √âtape 3: Red√©marrer l'application

```bash
npm run dev
```

### √âtape 4: Tester

1. Poser une question dans le chat
2. V√©rifier que la r√©ponse affiche les sources en bas
3. Cliquer sur un lien source pour v√©rifier qu'il fonctionne

## üìä Exemple de R√©ponse

**Question :** 
> Quels sont les documents requis pour un deletion certificate √† Malta ?

**R√©ponse avec sources :**

> D'apr√®s le [Document: Malta - Closure of Registry (PAVILLON_MALTA)], les documents requis sont:
> 
> 1. Application for Closure of Registry
> 2. Certificate of Registry original
> 3. Proof of ownership
> 4. Clearance from Customs
> 5. No Outstanding Fees Certificate
> 
> [Document: Malta - Termination registration small ships ‚â§24m (PAVILLON_MALTA)] pr√©cise...
>
> ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
> ‚öñÔ∏è DISCLAIMER L√âGAL:
> Les informations fournies sont √† titre informatif...
>
> ---
>
> **üìö Sources (2)**
>
> **[1] Malta - Closure of Registry (proc√©dure)**  
> üè∑Ô∏è PAVILLON_MALTA ‚Ä¢ Pertinence: 95%  
> üîó https://www.transport.gov.mt/maritime/ship-and-yacht-registry/ship-registration/closure-of-registry-130
>
> **[2] Malta - Termination registration small ships (‚â§24m)**  
> üè∑Ô∏è PAVILLON_MALTA ‚Ä¢ Pertinence: 95%  
> üîó https://www.transport.gov.mt/maritime/small-ships/small-ship-registration/voluntary-termination-of-registration-of-a-small-ship-

## ‚úÖ Checklist Post-Migration

- [ ] Migration SQL 013 appliqu√©e dans Supabase
- [ ] Fonction `search_documents()` retourne `source_url`
- [ ] Documents ont `source_url` renseign√© (query de v√©rification)
- [ ] Application red√©marr√©e
- [ ] Test chat: question pos√©e
- [ ] Sources affich√©es en bas du message
- [ ] Liens sources cliquables et fonctionnels

## üéØ T√©l√©chargement Automatique PDFs

**Question:** *Faut-il t√©l√©charger les PDFs manuellement ?*

**R√©ponse:** **NON ‚ùå**

Les PDFs sont t√©l√©charg√©s **automatiquement** par les scripts d'ingestion :

```typescript
// lib/web-scraper.ts
export async function downloadPDF(url: string): Promise<Buffer> {
  const response = await fetch(url)
  const arrayBuffer = await response.arrayBuffer()
  return Buffer.from(arrayBuffer)
}

// lib/pdf-parser.ts
export async function extractTextFromPDF(buffer: Buffer): Promise<PDFParseResult> {
  const data = await pdfParse(buffer)
  return {
    text: data.text,
    pages: data.numpages,
    metadata: { ... }
  }
}
```

**Process d'ingestion :**
1. ‚úÖ Script lit l'URL du PDF
2. ‚úÖ T√©l√©charge automatiquement via `fetch()`
3. ‚úÖ Extrait le texte avec `pdf-parse`
4. ‚úÖ G√©n√®re les embeddings
5. ‚úÖ Stocke dans Supabase

**Commandes d'ingestion :**

```bash
# Ing√©rer toutes les nouvelles sources radiation/pavillons
npm run ingest:radiation

# Ing√©rer une cat√©gorie sp√©cifique
npm run ingest:category -- PAVILLON_MALTA

# V√©rifier l'ingestion
npm run ingest:verify
```

## üöÄ R√©sultat Final

L'utilisateur voit maintenant:

‚úÖ R√©ponse Gemini avec **citations pr√©cises** dans le texte  
‚úÖ Section **üìö Sources (X)** en bas du message  
‚úÖ **Liens cliquables** vers les documents sources  
‚úÖ **Badge cat√©gorie** + **% de pertinence**  
‚úÖ **Aucune intervention manuelle** pour t√©l√©charger les PDFs

üéâ **Pr√™t pour production !**
