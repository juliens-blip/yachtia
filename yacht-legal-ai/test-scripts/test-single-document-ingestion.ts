/**
 * Test script: Ingest ONE document only to verify chunking + embedding pipeline
 * 
 * Purpose: Validate that:
 * 1. Document extraction works
 * 2. Chunking produces valid chunks
 * 3. Embeddings are generated (dim 768)
 * 4. Chunks are inserted into DB
 * 
 * Usage: npm run test:ingest:single
 */

// CRITICAL: Load env FIRST
import './load-env'

import { extractTextFromPDF } from '../lib/pdf-parser'
import { downloadPDF } from '../lib/web-scraper'
import { chunkText } from '../lib/chunker'
import { generateEmbedding } from '../lib/gemini'
import { supabaseAdmin } from '../lib/supabase'

const TEST_DOC = {
  name: 'CYC Code - Complete 2020/2025 Edition',
  url: 'https://www.yachtmca.com/wp-content/uploads/2020/09/CYC-Code-Complete-2020-Edition.pdf',
  type: 'pdf' as const,
  category: 'PAVILLON_MALTA'
}

async function main() {
  console.log('ğŸ§ª Test d\'ingestion d\'un seul document\n')
  console.log(`ğŸ“„ Document: ${TEST_DOC.name}`)
  console.log(`ğŸ”— URL: ${TEST_DOC.url}`)
  console.log(`ğŸ“‚ CatÃ©gorie: ${TEST_DOC.category}\n`)

  try {
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // STEP 1: Download PDF
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    console.log('â¬‡ï¸  Step 1/5: Downloading PDF...')
    const buffer = await downloadPDF(TEST_DOC.url)
    console.log(`   âœ… Downloaded ${(buffer.length / 1024).toFixed(1)} KB\n`)

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // STEP 2: Extract text
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    console.log('ğŸ“– Step 2/5: Extracting text from PDF...')
    const parsed = await extractTextFromPDF(buffer)
    const text = parsed.text.replace(/\u0000/g, '').replace(/[\uD800-\uDFFF]/g, '')
    console.log(`   âœ… Extracted ${parsed.pages} pages`)
    console.log(`   âœ… Text length: ${text.length} characters\n`)

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // STEP 3: Chunk text
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    console.log('âœ‚ï¸  Step 3/5: Chunking text...')
    const chunks = chunkText(text, 500, 200)
    console.log(`   âœ… Created ${chunks.length} chunks`)
    
    if (chunks.length > 0) {
      console.log(`   ğŸ“Š First chunk:`)
      console.log(`      - Index: ${chunks[0].index}`)
      console.log(`      - Token count: ${chunks[0].tokenCount}`)
      console.log(`      - Section: ${chunks[0].metadata.section}`)
      console.log(`      - Headers: ${chunks[0].metadata.headers.join(', ')}`)
      console.log(`      - Preview: "${chunks[0].text.slice(0, 100)}..."\n`)
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // STEP 4: Generate embeddings (test on first 3 chunks only)
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    console.log('ğŸ§® Step 4/5: Generating embeddings (first 3 chunks)...')
    const testChunks = chunks.slice(0, 3)
    
    const embeddings = await Promise.all(
      testChunks.map(chunk => generateEmbedding(chunk.text))
    )
    
    console.log(`   âœ… Generated ${embeddings.length} embeddings`)
    embeddings.forEach((emb, i) => {
      console.log(`      - Embedding ${i}: dim=${emb.length}, first 5 values=[${emb.slice(0, 5).map(v => v.toFixed(4)).join(', ')}...]`)
    })
    console.log()

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // STEP 5: Insert into DB (test with first 3 chunks)
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    console.log('ğŸ’¾ Step 5/5: Inserting into database...')
    
    // First, insert document
    const { data: document, error: docError } = await supabaseAdmin
      .from('documents')
      .insert({
        name: `[TEST] ${TEST_DOC.name}`,
        category: TEST_DOC.category,
        pages: parsed.pages,
        file_url: TEST_DOC.url,
        source_url: TEST_DOC.url,
        is_public: true,
        metadata: {
          source: TEST_DOC.url,
          type: TEST_DOC.type,
          language: 'en',
          ingested_at: new Date().toISOString(),
          test_run: true
        }
      })
      .select('id')
      .single()

    if (docError || !document) {
      throw new Error(`Failed to insert document: ${docError?.message || 'Unknown error'}`)
    }

    console.log(`   âœ… Document inserted with ID: ${document.id}`)

    // Then, insert chunks
    const chunkRecords = testChunks.map((chunk, i) => ({
      document_id: document.id,
      chunk_index: i,
      chunk_text: chunk.text,
      chunk_vector: embeddings[i],
      page_number: chunk.metadata.page,
      token_count: chunk.tokenCount
    }))

    const { error: chunksError } = await supabaseAdmin
      .from('document_chunks')
      .insert(chunkRecords)

    if (chunksError) {
      throw new Error(`Failed to insert chunks: ${chunksError.message}`)
    }

    console.log(`   âœ… ${chunkRecords.length} chunks inserted into database\n`)

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // VERIFICATION
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    console.log('ğŸ” Verification...')
    
    const { count, error: countError } = await supabaseAdmin
      .from('document_chunks')
      .select('*', { count: 'exact', head: true })
      .eq('document_id', document.id)

    if (!countError) {
      console.log(`   âœ… Confirmed: ${count} chunks in database for this document\n`)
    }

    console.log('âœ… TEST COMPLETED SUCCESSFULLY\n')
    console.log('ğŸ“‹ Summary:')
    console.log(`   - Document pages: ${parsed.pages}`)
    console.log(`   - Text extracted: ${text.length} chars`)
    console.log(`   - Total chunks created: ${chunks.length}`)
    console.log(`   - Test chunks inserted: ${testChunks.length}`)
    console.log(`   - Embedding dimension: ${embeddings[0]?.length}`)
    console.log('\nğŸ’¡ Next step: Run full ingestion with `npm run ingest:all`\n')

    process.exit(0)

  } catch (error) {
    console.error('\nâŒ TEST FAILED\n')
    console.error(error)
    process.exit(1)
  }
}

main()
