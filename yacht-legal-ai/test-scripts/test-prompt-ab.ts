/**
 * T27 - A/B Testing Prompts
 * Compare 2 variantes de prompts pour qualit√© des citations
 */

import assert from 'node:assert/strict'

// Types
interface PromptVariant {
  name: string
  description: string
  systemPrompt: string
}

interface TestQuery {
  question: string
  expectedTopics: string[]
}

interface ABTestResult {
  variantName: string
  query: string
  citationCount: number
  uniqueSources: string[]
  hasPageNumbers: boolean
  hasCodePriority: boolean
  score: number
  issues: string[]
}

interface ABSummary {
  variantA: { name: string; avgScore: number; totalCitations: number }
  variantB: { name: string; avgScore: number; totalCitations: number }
  winner: string
  recommendation: string
}

// Variante A: Prompt actuel (V3 standard)
const PROMPT_VARIANT_A: PromptVariant = {
  name: 'V3_Standard',
  description: 'Prompt V3 avec r√®gles strictes citations',
  systemPrompt: `Tu es un assistant juridique maritime expert.

R√àGLES STRICTES:
1. MINIMUM 3 CITATIONS OBLIGATOIRES au format: [Source: NOM_DOCUMENT, page X, section Y]
2. LIRE INT√âGRALEMENT tous les chunks fournis
3. FUSION MULTI-SOURCES: Croiser CODE + OGSR + GUIDE
4. JAMAIS utiliser internet
5. Si info manquante: lister tous les docs analys√©s

HI√âRARCHIE SOURCES:
1. Codes juridiques (LY3, REG, CYC, MLC, SOLAS)
2. OGSR/Lois nationales
3. Guides professionnels
4. Articles techniques`
}

// Variante B: Prompt enrichi avec few-shot am√©lior√©
const PROMPT_VARIANT_B: PromptVariant = {
  name: 'V3_Enhanced',
  description: 'Prompt V3 avec few-shot enrichi et scoring explicite',
  systemPrompt: `Tu es un assistant juridique maritime expert.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
SCORING QUALIT√â R√âPONSE (auto-√©valuation obligatoire)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Avant de r√©pondre, calcule mentalement ton score:
- 5+ sources cit√©es = +10 points
- Codes prioritaires cit√©s = +5 points par code
- Page + section pour chaque citation = +2 points par citation
- Croisement 3 types sources (CODE/OGSR/GUIDE) = +10 points
- Formulation vague ("g√©n√©ralement", "typiquement") = -5 points

MINIMUM REQUIS: 25 points

R√àGLES ABSOLUES:
1. MINIMUM 5 CITATIONS avec page et section
2. CODES CIT√âS = PRIORIT√â ABSOLUE (LY3 > OGSR > Guide)
3. Format strict: [Source: NOM_DOCUMENT, page X, section Y]
4. INTERDICTION: citations web, formulations vagues

FEW-SHOT EXEMPLAIRE (score: 32 points):

Question: "Inspection yacht 45m Malta construit 2000"

R√©ponse:
Pour un yacht de 45m construit en 2000 (24 ans):

**Inspections selon √¢ge:**
[Source: Malta CYC 2020, page 8, section 4.2] Yachts >20 ans: inspection annuelle renforc√©e obligatoire.
[Source: LY3 Large Yacht Code, page 32, section 5.1] Inspections structure tous les 5 ans apr√®s 15 ans.

**Exigences taille:**
[Source: SOLAS Chapter II-1, page 45, section 12] Navires >24m: certificats s√©curit√© obligatoires.
[Source: MLC 2006, page 44, section A2.3] Manning minimum selon jauge.

**Proc√©dure Malta:**
[Source: Malta Registration Process, page 6, section 4.1] Documents: Certificate of Inspection, Class Certificate, Survey Report.

Score: 5 sources √ó 5 + 2 codes prioritaires √ó 5 + croisement = 35 points ‚úì`
}

// Queries de test
const TEST_QUERIES: TestQuery[] = [
  {
    question: 'Immatriculation yacht commercial 50m √† Malta',
    expectedTopics: ['√©ligibilit√©', 'documents', 'inspection', 'SOLAS']
  },
  {
    question: 'Exigences manning selon LY3 pour yacht 35m',
    expectedTopics: ['LY3', '√©quipage', 'minimum', 'certificat']
  },
  {
    question: 'Diff√©rences entre REG Yacht Code et CYC Malta',
    expectedTopics: ['REG', 'CYC', 'comparaison', 'applicabilit√©']
  },
  {
    question: 'Inspections pour yacht construit en 1995 (30 ans)',
    expectedTopics: ['√¢ge', 'inspection', 'renforc√©e', 'structure']
  }
]

// Simulation de r√©ponses (pour test offline)
function simulateResponse(variant: PromptVariant, query: TestQuery): string {
  if (variant.name === 'V3_Standard') {
    return `
Pour r√©pondre √† votre question sur "${query.question}":

[Source: Malta CYC 2020, page 12, section 3.1] Les exigences g√©n√©rales s'appliquent.
[Source: LY3 Large Yacht Code, page 8, section 2.4] Les normes de s√©curit√© sont d√©finies.
[Source: Malta OGSR Part III, page 15, section 12.2] L'√©ligibilit√© est pr√©cis√©e.

Ces informations couvrent les aspects principaux de ${query.expectedTopics.slice(0, 2).join(' et ')}.

‚öñÔ∏è **Disclaimer**: Consultez un avocat maritime qualifi√©.
    `
  } else {
    return `
Pour un ${query.question} (analyse compl√®te):

**Cadre r√©glementaire principal:**
[Source: Malta CYC 2020, page 12, section 3.1] D√©finition des cat√©gories de yachts commerciaux.
[Source: LY3 Large Yacht Code, page 8, section 2.4] Standards internationaux applicables.

**Exigences sp√©cifiques:**
[Source: Malta OGSR Part III, page 15, section 12.2] Crit√®res d'√©ligibilit√© propri√©taire.
[Source: Malta Merchant Shipping Act 1973, page 23, section 34] Cadre l√©gal national.

**Proc√©dures et documents:**
[Source: Malta Ship Registry Procedures, page 6, section 4.1] Liste documents requis.
[Source: MLC 2006, page 44, section A2.3] Exigences manning si applicable.

Score auto-√©valu√©: 35 points (6 sources √ó 5 + 2 codes √ó 5 + croisement) ‚úì

‚öñÔ∏è **Disclaimer**: Consultez un avocat maritime qualifi√©.
    `
  }
}

// Analyse d'une r√©ponse
function analyzeResponse(response: string, variant: string, query: string): ABTestResult {
  const issues: string[] = []

  // Extraction citations
  const citationPattern = /\[Source:\s*([^,\]]+)(?:,\s*page\s*(\d+))?(?:,\s*section\s*([^\]]+))?\]/gi
  const citations: Array<{ source: string; hasPage: boolean; hasSection: boolean }> = []
  let match: RegExpExecArray | null

  const regex = new RegExp(citationPattern.source, 'gi')
  while ((match = regex.exec(response)) !== null) {
    citations.push({
      source: match[1]?.trim() || '',
      hasPage: !!match[2],
      hasSection: !!match[3]
    })
  }

  const uniqueSources = [...new Set(citations.map(c => c.source))]
  const citationCount = uniqueSources.length
  const hasPageNumbers = citations.every(c => c.hasPage)

  // V√©rifier priorit√© codes
  const codePriority = ['LY3', 'CYC', 'REG', 'SOLAS', 'MLC', 'MARPOL']
  const hasCodePriority = codePriority.some(code =>
    uniqueSources.some(s => s.toUpperCase().includes(code))
  )

  // Calcul score
  let score = 0
  score += citationCount * 5 // 5 points par source unique
  score += hasPageNumbers ? 10 : 0
  score += hasCodePriority ? 10 : 0

  // P√©nalit√©s
  if (/g√©n√©ralement|typiquement/i.test(response)) {
    score -= 5
    issues.push('Formulation vague d√©tect√©e')
  }
  if (citationCount < 3) {
    score -= 10
    issues.push('Moins de 3 citations')
  }

  return {
    variantName: variant,
    query,
    citationCount,
    uniqueSources,
    hasPageNumbers,
    hasCodePriority,
    score,
    issues
  }
}

// Ex√©cution A/B test
async function runABTest(): Promise<ABSummary> {
  console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
  console.log('  T27 - A/B Testing Prompts')
  console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n')

  const resultsA: ABTestResult[] = []
  const resultsB: ABTestResult[] = []

  for (const query of TEST_QUERIES) {
    console.log(`\nüìã Query: "${query.question}"`)
    console.log('‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ')

    // Test Variante A
    const responseA = simulateResponse(PROMPT_VARIANT_A, query)
    const resultA = analyzeResponse(responseA, PROMPT_VARIANT_A.name, query.question)
    resultsA.push(resultA)

    console.log(`  [A] ${PROMPT_VARIANT_A.name}: ${resultA.citationCount} citations, score=${resultA.score}`)
    if (resultA.issues.length > 0) {
      console.log(`      Issues: ${resultA.issues.join(', ')}`)
    }

    // Test Variante B
    const responseB = simulateResponse(PROMPT_VARIANT_B, query)
    const resultB = analyzeResponse(responseB, PROMPT_VARIANT_B.name, query.question)
    resultsB.push(resultB)

    console.log(`  [B] ${PROMPT_VARIANT_B.name}: ${resultB.citationCount} citations, score=${resultB.score}`)
    if (resultB.issues.length > 0) {
      console.log(`      Issues: ${resultB.issues.join(', ')}`)
    }
  }

  // Calcul moyennes
  const avgScoreA = resultsA.reduce((sum, r) => sum + r.score, 0) / resultsA.length
  const avgScoreB = resultsB.reduce((sum, r) => sum + r.score, 0) / resultsB.length
  const totalCitationsA = resultsA.reduce((sum, r) => sum + r.citationCount, 0)
  const totalCitationsB = resultsB.reduce((sum, r) => sum + r.citationCount, 0)

  const winner = avgScoreB > avgScoreA ? PROMPT_VARIANT_B.name : PROMPT_VARIANT_A.name
  const improvement = ((Math.max(avgScoreA, avgScoreB) - Math.min(avgScoreA, avgScoreB)) / Math.min(avgScoreA, avgScoreB) * 100).toFixed(1)

  const summary: ABSummary = {
    variantA: { name: PROMPT_VARIANT_A.name, avgScore: avgScoreA, totalCitations: totalCitationsA },
    variantB: { name: PROMPT_VARIANT_B.name, avgScore: avgScoreB, totalCitations: totalCitationsB },
    winner,
    recommendation: avgScoreB > avgScoreA
      ? `Adopter ${PROMPT_VARIANT_B.name} (+${improvement}% qualit√© citations)`
      : `Conserver ${PROMPT_VARIANT_A.name} (stable)`
  }

  // Affichage r√©sum√©
  console.log('\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
  console.log('  R√âSUM√â A/B TEST')
  console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
  console.log(`  Variante A (${PROMPT_VARIANT_A.name}):`)
  console.log(`    - Score moyen: ${avgScoreA.toFixed(1)}`)
  console.log(`    - Total citations: ${totalCitationsA}`)
  console.log(`  Variante B (${PROMPT_VARIANT_B.name}):`)
  console.log(`    - Score moyen: ${avgScoreB.toFixed(1)}`)
  console.log(`    - Total citations: ${totalCitationsB}`)
  console.log(`\n  üèÜ Gagnant: ${winner}`)
  console.log(`  üìä Recommandation: ${summary.recommendation}`)
  console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n')

  return summary
}

// Export
export { PROMPT_VARIANT_A, PROMPT_VARIANT_B, runABTest, analyzeResponse }
export type { ABTestResult, ABSummary }

// Ex√©cution
runABTest().catch(error => {
  console.error('‚ùå A/B Test failed:', error)
  process.exit(1)
})
